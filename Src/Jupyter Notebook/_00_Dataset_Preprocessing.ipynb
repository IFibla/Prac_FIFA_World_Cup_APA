{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing\n",
    "\n",
    "In this notebook we are performing all the tasks related with the datapreprocessing. We start by checking the missing values and the outliers and then, once they are detected, we delete it from our dataset. Finnaly, we transform the categorical columns into values as it would be easy for our models to get results if those columns are integers rather than strings. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_information_about_dataset(df):\n",
    "    for it, key in enumerate(df.keys()): print(it, key, len(df[df[key].notna()]))\n",
    "    print('From the dataset, after deleting the NaN values, we have found that we have only', \n",
    "            len(df[~df.isnull().any(axis=1)]), 'rows remaining.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_from_dataframe(df, delete_keys):\n",
    "    for key in delete_keys:\n",
    "        del df[key]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_string_to_int_dataframe(df, keys, input):\n",
    "    for keys, inp in zip(keys, input):\n",
    "        df[keys].replace(inp, list(range(len(inp))), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dictionary(df, key, continue_list=None):\n",
    "    result = dict()\n",
    "    for _key, _val in zip(df[key].keys(), df[key].values):\n",
    "        if _key not in continue_list:\n",
    "            result[_key] = _val\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(df, plot=0):\n",
    "    corr_matrix = df.corr()\n",
    "\n",
    "    home_team = dataframe_to_dictionary(corr_matrix, 'home_team_score', ['home_team_score', 'away_team_score'])\n",
    "    away_team = dataframe_to_dictionary(corr_matrix, 'away_team_score', ['home_team_score', 'away_team_score'])\n",
    "\n",
    "    home_team = dict(sorted(home_team.items(), key=lambda item: item[1]))\n",
    "    away_team = dict(sorted(away_team.items(), key=lambda item: item[1]))\n",
    "    if plot == 0:\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(3, 1)\n",
    "        ax0.matshow(corr_matrix)\n",
    "        ax0.set_title('Correlation Matrix', fontsize=8)\n",
    "        ax0.set_xticklabels(list(range(len(corr_matrix.keys()))), fontsize=5)\n",
    "        ax0.set_yticklabels(list(corr_matrix.keys()), fontsize=5)\n",
    "\n",
    "        ax1.set_title('Home Team Variables Correlation', fontsize=8)\n",
    "        ax1.barh(list(home_team.keys()), list(home_team.values()))\n",
    "        ax1.set_yticklabels(list(home_team.keys()), fontsize=5)\n",
    "        \n",
    "        ax2.set_title('Away Team Variables Correlation', fontsize=8)\n",
    "        ax2.barh(list(away_team.keys()), list(away_team.values()))\n",
    "        ax2.set_yticklabels(list(away_team.keys()), fontsize=5)\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "    elif plot == 1:\n",
    "        plt.matshow(corr_matrix)\n",
    "        plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
    "        plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "        plt.colorbar()\n",
    "\n",
    "    elif plot == 2:\n",
    "        plt.title('Home Team Variables Correlation')\n",
    "        plt.barh(list(home_team.keys()), list(home_team.values()))\n",
    "        plt.yticks(list(home_team.keys()))\n",
    "    elif plot == 3:\n",
    "        plt.title('Away Team Variables Correlation')\n",
    "        plt.barh(list(away_team.keys()), list(away_team.values()))\n",
    "        plt.yticks(list(away_team.keys()))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/international_matches.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_information_about_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_NaN = df[~df.isnull().any(axis=1)]\n",
    "df_without_NaN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_NaN_UnusedVars = copy.deepcopy(df_without_NaN)\n",
    "delete_keys = ['date', 'home_team', 'away_team', 'tournament', 'city', 'country', 'neutral_location', 'home_team_result']\n",
    "df_without_NaN_UnusedVars = delete_from_dataframe(df_without_NaN_UnusedVars, delete_keys)\n",
    "df_without_NaN_UnusedVars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_NaN_UnusedVars_KeysReplaced = copy.deepcopy(df_without_NaN_UnusedVars)\n",
    "replace_keys = ['home_team_continent', 'away_team_continent', 'shoot_out']\n",
    "replace_input = [['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America'], ['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America'], ['No', 'Yes']]\n",
    "df_without_NaN_UnusedVars_KeysReplaced = replace_string_to_int_dataframe(df_without_NaN_UnusedVars_KeysReplaced, replace_keys, replace_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(df_without_NaN_UnusedVars_KeysReplaced, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_NaN_UnusedVars_KeysReplaced.to_csv('../../Data/international_matches_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AprenentatgeAutomatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "051e2a7455ef7de55727fc6194105a963458f6ab7bfa3795f7d8c3e8e4a34bf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
